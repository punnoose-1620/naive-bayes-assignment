{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NxM_QjATq0Ti"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SfCeReq8BX"
      },
      "source": [
        "# Step 1: Load the CSV data\n",
        "# Replace 'data.csv' with your actual CSV file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7U4hbOErq2HF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], dtype='object')\n",
            "<bound method NDFrame.head of     sepal length sepal width petal length petal width           class\n",
            "0              r           r            r           r               n\n",
            "1            5.1         3.5          1.4         0.2     Iris-setosa\n",
            "2            4.9         3.0          1.4         0.2     Iris-setosa\n",
            "3            4.7         3.2          1.3         0.2     Iris-setosa\n",
            "4            4.6         3.1          1.5         0.2     Iris-setosa\n",
            "..           ...         ...          ...         ...             ...\n",
            "146          6.7         3.0          5.2         2.3  Iris-virginica\n",
            "147          6.3         2.5          5.0         1.9  Iris-virginica\n",
            "148          6.5         3.0          5.2         2.0  Iris-virginica\n",
            "149          6.2         3.4          5.4         2.3  Iris-virginica\n",
            "150          5.9         3.0          5.1         1.8  Iris-virginica\n",
            "\n",
            "[151 rows x 5 columns]>\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('iris.csv')\n",
        "print(data.columns)\n",
        "print(data.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u359wmdZrBZm"
      },
      "source": [
        "# Assuming the last column is the target and the rest are features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v3dyJHE0q315"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwC9Oa3VrEHc"
      },
      "source": [
        "# Step 2: Preprocess the data\n",
        "# Convert categorical data to numerical if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ToQ8pZ8mq5nl"
      },
      "outputs": [],
      "source": [
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = y.astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SptN7czrHyg"
      },
      "source": [
        "# Step 3: Naive Bayes Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6IBeHKFrLO3"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        self.feature_stats = {}\n",
        "        self.class_prior = {}\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X[y == c]\n",
        "            self.feature_stats[c] = {\n",
        "                \"mean\": X_c.mean(axis=0),\n",
        "                \"var\": X_c.var(axis=0)\n",
        "            }\n",
        "            self.class_prior[c] = len(X_c) / len(y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        posteriors = []\n",
        "\n",
        "        for x in X:\n",
        "            class_probs = []\n",
        "            for c in self.classes:\n",
        "                prior = np.log(self.class_prior[c])\n",
        "                likelihood = -0.5 * np.sum(\n",
        "                    np.log(2 * np.pi * self.feature_stats[c][\"var\"]) +\n",
        "                    ((x - self.feature_stats[c][\"mean\"]) ** 2) / (2 * self.feature_stats[c][\"var\"])\n",
        "                )\n",
        "                class_probs.append(prior + likelihood)\n",
        "            posteriors.append(self.classes[np.argmax(class_probs)])\n",
        "\n",
        "        return np.array(posteriors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d8vWxMArNa9"
      },
      "source": [
        "# Step 4: Split the data into train-test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGtMq2g9rYv4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3IDGOoPrabK"
      },
      "source": [
        "# Step 5: Train and Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SqE0iVHrckN"
      },
      "outputs": [],
      "source": [
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-GCP0mireHf"
      },
      "source": [
        "# Step 6: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZYMWi0ArgDa"
      },
      "outputs": [],
      "source": [
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k_L29Enrh9F"
      },
      "source": [
        "# Optional: Plot a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4M9yoC3qu7u"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
